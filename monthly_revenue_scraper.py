import requests
import pandas as pd
from io import StringIO # å°å…¥ StringIO

def fetch_stock_data(url: str, headers: dict, table_id: str) -> pd.DataFrame | None:
    """
    è¨ªå•ç›®æ¨™ URL ä¸¦çˆ¬å–æŒ‡å®šçš„è¡¨æ ¼è³‡æ–™ã€‚

    Args:
        url (str): è¦çˆ¬å–çš„ç¶²å€ã€‚
        headers (dict): åŒ…å« User-Agent å’Œ Cookie çš„è«‹æ±‚æ¨™é ­ã€‚
        table_id (str): è¦æŠ“å–çš„ <table> æ¨™ç±¤çš„ idã€‚

    Returns:
        pd.DataFrame | None: æˆåŠŸå‰‡å›å‚³ DataFrameï¼Œå¤±æ•—å‰‡å›å‚³ Noneã€‚
    """
    print(f"ğŸ”„ æ­£åœ¨å˜—è©¦é€£ç·šåˆ°ç›®æ¨™ç¶²å€...")
    
    # 1. ä½¿ç”¨ requests.Session() ä¾†ä¿æŒé€£ç·šç‹€æ…‹ (Cookies)
    session = requests.Session()
    session.headers.update(headers)
    
    try:
        # 2. ç™¼é€ GET è«‹æ±‚ (è¨­å®š timeout é¿å…ç„¡æ­¢ç›¡ç­‰å¾…)
        response = session.get(url, timeout=15)
        
        # æª¢æŸ¥ HTTP ç‹€æ…‹ç¢¼ï¼Œ4xx æˆ– 5xx æœƒè§¸ç™¼ä¾‹å¤–
        response.raise_for_status()
        
        # 3. ç¢ºä¿å›æ‡‰å…§å®¹ç‚º UTF-8 ç·¨ç¢¼
        response.encoding = 'utf-8'
        html_content = response.text
        
        print("âœ… é€£ç·šæˆåŠŸï¼Œæ­£åœ¨è§£æè¡¨æ ¼...")

        # 4. [é—œéµ] è§£æè³‡æ–™ 
        # ä½¿ç”¨ StringIO åŒ…è£ html_content ä¾†æ¶ˆé™¤ FutureWarning
        tables = pd.read_html(
            StringIO(html_content), 
            flavor='lxml', 
            attrs={'id': table_id}
        )
        
        # 5. å–å¾— DataFrame
        df = tables[0]
        
        print(f"ğŸ‰ æˆåŠŸè§£æè³‡æ–™ï¼å…± {len(df)} ç­†ã€‚")
        return df

    # 6. å®Œæ•´çš„éŒ¯èª¤è™•ç†
    except requests.exceptions.HTTPError as http_err:
        print(f"âŒ HTTP éŒ¯èª¤: {http_err}")
        if response.status_code == 403:
            print("ğŸ‘‰ (403 Forbidden) å­˜å–è¢«æ‹’ã€‚è«‹æª¢æŸ¥æ‚¨çš„ Cookie æ˜¯å¦æ­£ç¢ºæˆ–å·²å¤±æ•ˆã€‚")
        elif response.status_code == 404:
            print("ğŸ‘‰ (404 Not Found) æ‰¾ä¸åˆ°é é¢ï¼Œè«‹æª¢æŸ¥ URLã€‚")
    except requests.exceptions.ConnectionError as conn_err:
        print(f"âŒ é€£ç·šéŒ¯èª¤: {conn_err}")
    except requests.exceptions.Timeout:
        print("âŒ è«‹æ±‚è¶…æ™‚ (Timeout)ã€‚")
    except IndexError:
        print(f"âŒ åš´é‡éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°è¡¨æ ¼ (list index out of range)ã€‚")
        print(f"ğŸ‘‰ é€™å¹¾ä¹å¯ä»¥è‚¯å®šæ˜¯ Cookie å¤±æ•ˆï¼Œå°è‡´çˆ¬èŸ²æŠ“åˆ°ã€Œç™»å…¥é ã€è€Œéè³‡æ–™é ã€‚")
    except Exception as e:
        print(f"âŒ ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤: {e}")
        
    return None

# --- [æ–°å‡½å¼] ç¬¦åˆ streamlit_app.py å°å…¥éœ€æ±‚çš„å‡½å¼ ---
def scrape_goodinfo() -> pd.DataFrame | None:
    """
    å°ˆé–€ç”¨æ–¼çˆ¬å– Goodinfoã€Œæœˆç‡Ÿæ”¶é¸è‚¡ã€é é¢çš„ä¸»å‡½å¼ã€‚
    æ­¤å‡½å¼æœƒè‡ªå‹•å¸¶å…¥å›ºå®šçš„ URL, Headers, å’Œ Table IDã€‚
    
    Returns:
        pd.DataFrame | None: çˆ¬å–åˆ°çš„è³‡æ–™ï¼Œå¤±æ•—å‰‡ç‚º Noneã€‚
    """
    
    # 1. ç›®æ¨™ç¶²å€
    TARGET_URL = "https://goodinfo.tw/tw/StockListFilter/StockList.asp?STEP=DATA&MARKET_CAT=%E8%87%AA%E8%A8%82%E7%AF%A9%E9%81%B8&INDUSTRY_CAT=%E6%88%91%E7%9A%84%E6%A2%9D%E4%BB%B6&SHEET=%E7%87%9F%E6%94%B6%E7%8B%80%E6%B3%81&SHEET2=%E6%9C%88%E7%87%9F%E6%94%B6%E7%8B%80%E6%B3%81&FL_SHEET=%E5%B9%B4%E7%8D%B2%E5%88%A9%E8%83%BD%E5%8A%9B&FL_SHEET2=%E7%8D%B2%E5%88%A9%E8%83%BD%E5%8A%9B&FL_MARKET=%E4%B8%8A%E5%B8%82%2F%E4%B8%8A%E6%AB%83&MY_FL_RULE_NM=%E6%9C%88%E7%87%9F%E6%94%B6%E9%81%B8%E8%82%A103&FL_ITEM0=%E5%96%AE%E6%9C%88%E7%87%9F%E6%94%B6%E5%B9%B4%E5%A2%9E%E7%8E%87%28%25%29%E2%80%93%E7%95%B6%E6%9C%88&FL_VAL_S0=15&FL_ITEM1=%E5%96%AE%E6%9C%88%E7%87%9F%E6%94%B6%E5%B9%B4%E5%A2%9E%E7%8E%87%28%25%29%E2%80%93%E5%89%8D1%E6%9C%88&FL_VAL_S1=10&FL_ITEM2=%E5%96%AE%E6%9C%88%E7%87%9F%E6%94%B6%E5%B9%B4%E5%A2%9E%E7%8E%87%28%25%29%E2%80%93%E5%89%8D2%E6%9C%88&FL_VAL_S2=10&FL_ITEM3=%E5%96%AE%E6%9C%88%E7%87%9F%E6%94%B6%E5%B9%B4%E5%A2%9E%E7%8E%87%28%25%29%E2%80%93%E5%89%8D3%E6%9C%88&FL_VAL_S3=10&FL_ITEM4=%E5%96%AE%E6%9C%88%E7%87%9F%E6%94%B6%E5%B9%B4%E5%A2%9E%E7%8E%87%28%25%29%E2%80%93%E5%89%8D4%E6%9C%88&FL_VAL_S4=10&FL_RULE0=%E6%9C%88%E7%87%9F%E6%94%B6%7C%7C%E5%96%AE%E6%9C%88%E7%87%9F%E6%94%B6%E5%89%B5%E6%AD%B7%E5%B9%B4%E5%90%8C%E6%9C%9F%E5%89%8D3%E9%AB%98%40%40%E6%9C%88%E7%87%9F%E6%94%B6%E5%89%B5%E6%8E%92%E5%90%8D%E7%B4%80%E9%8C%84%40%40%E5%96%AE%E6%9C%88%E7%87%9F%E6%94%B6%E5%89%B5%E6%AD%B7%E5%B9%B4%E5%90%8C%E6%9C%9F%E5%89%8D3%E9%AB%98&FL_FD0=%7C%7C1%7C%7C0%7C%7C%3D%7C%7C%7C%7C1%7C%7C0&FL_FD1=%7C%7C1%7C%7C0%7C%7C%3D%7C%7C%7C%7C1%7C%7C0&FL_FD2=%7C%7C1%7C%7C0%7C%7C%3D%7C%7C%7C%7C1%7C%7C0&FL_FD3=%7C%7C1%7C%7C0%7C%7C%3D%7C%7C%7C%7C1%7C%7C0&FL_FD4=%7C%7C1%7C%7C0%7C%7C%3D%7C%7C%7C%7C1%7C%7C0&FL_FD5=%7C%7C1%7C%7C0%7C%7C%3D%7C%7C%7C%7C1%7C%7C0&IS_RELOAD_REPORT=T"
    
    # 2. ç›®æ¨™è¡¨æ ¼ ID
    TABLE_ID = "#divStockList"
    
    # 3. è«‹æ±‚æ¨™é ­
    HEADERS = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36",
        "Cookie": "__qca=I0-2120255871-1765697107313; CLIENT%5FID=20251110163553320%5F114%2E37%2E222%2E90; _ga=GA1.1.832428120.1762763765; _cc_id=ada7690de47741c349f179f457208c78; LOGIN=EMAIL=yjc5760%40gmail%2Ecom&USER%5FNM=YJ+Chen&ACCOUNT%5FID=107359590931917990151&ACCOUNT%5FVENDOR=Google&NO%5FEXPIRE=T; IS_TOUCH_DEVICE=F; SCREEN_SIZE=WIDTH=1920&HEIGHT=1080; panoramaId_expiry=1766301878708; panoramaId=9e81e8765c9bd09c413245655ac1185ca02c4a4dd131c4f03e107d1ddf5200a4; panoramaIdType=panoDevice; __gads=ID=26c4020a504f4925:T=1762763767:RT=1765697079:S=ALNI_MYlg_2Y6k-m7aDIXN1sqaq0pis3Yw; __gpi=UID=000011b284b2036e:T=1762763767:RT=1765697079:S=ALNI_MbFAko50gF8iaVeMc75CATgrEO8MQ; __eoi=ID=7b4c554b1803ff64:T=1762763767:RT=1765697079:S=AA-AfjaRA69ugEU-b6Qdv3vI8WTB; FCCDCF=%5Bnull%2Cnull%2Cnull%2Cnull%2Cnull%2Cnull%2C%5B%5B32%2C%22%5B%5C%224073ca81-6853-4cdc-b16a-44f26bfae1c0%5C%22%2C%5B1762763765%2C349000000%5D%5D%22%5D%5D%5D; cto_bidid=b2hFhV9OQVQ0ZUo4V2t5cndUc3E3ejdqWEJKd1FHT3JhZFk0bDhHVmdydEhTWTFlQjBlenBTdlBwRnlRTmV3d0lqaVVZT1l0VUdHOEFhbmRaeVludDdqcnN6WnQweWZ3SFRYM3FsejhWSjJOajdsMCUzRA; FCNEC=%5B%5B%22AKsRol9Bt7FsXXKtCJF8UwBni-lrqnqPD0nYZur4YWfypR8gHChWKzv8n8K7GpvMHYuXxg4m0Lzw0hDnOVGe5BVrb7yVckln82lXSPN4yDo_3jYImevURBqgCICUAEBs5gibJ2Gjts3uMyoCkZ5xCuyXCfJs2zZ5Dg%3D%3D%22%5D%5D; cto_bundle=5nQkw180ZHJ6RVJQd3VzalVnakZybTFaUG1FVGFySlVZRzRWeDJtM0JycXVVYzFSWlNPeDk3dXUzVENCWVlhNVlLc0hnNGt3JTJGbjZhbUtkUTJOUkIyc21OdTNVR3JUTG5XVkRXazRETXd5YXE4SHBlVHdTWnVVMVFCTlJTVjc1TmZKcDJKWHZxRmlidzBKTlhjZW1Md0g0amhiQSUzRCUzRA; SESSION%5FVAL=55647860%2E27; _ga_0LP5MLQS7E=GS2.1.s1765697076$o3$g1$t1765697251$j57$l0$h0" 
    }
    
    # 4. åŸ·è¡Œçˆ¬èŸ²
    data_df = fetch_stock_data(TARGET_URL, HEADERS, TABLE_ID)
    
    # 5. [é—œéµä¿®å¾©] è™•ç† Goodinfo ç‰¹æœ‰çš„å¤šå±¤æ¨™é ­ (MultiIndex)
    if data_df is not None:
        try:
            # Goodinfo çš„è¡¨æ ¼å¸¸æœ‰ 2 å±¤æ¨™é ­ (MultiIndex)
            # æˆ‘å€‘åªéœ€è¦ç¬¬äºŒå±¤ (level 1)ï¼Œå®ƒæ‰åŒ…å« 'ä»£ç¢¼', 'åç¨±'
            if isinstance(data_df.columns, pd.MultiIndex):
                print("â„¹ï¸ æª¢æ¸¬åˆ°å¤šå±¤æ¨™é ­ (MultiIndex)ï¼Œæ­£åœ¨é€²è¡Œç°¡åŒ–...")
                new_columns = data_df.columns.get_level_values(1)
                
                # è™•ç†é‡è¤‡æ¬„ä½
                if not new_columns.is_unique:
                    print("âš ï¸ æª¢æ¸¬åˆ°é‡è¤‡çš„æ¬„ä½åç¨±ï¼Œå°‡å˜—è©¦å»é‡è¤‡ã€‚")
                    seen = set()
                    final_cols = []
                    for col in new_columns:
                        if col in seen:
                            i = 1
                            new_col = f"{col}_{i}"
                            while new_col in seen:
                                i += 1
                                new_col = f"{col}_{i}"
                            final_cols.append(new_col)
                            seen.add(new_col)
                        else:
                            final_cols.append(col)
                            seen.add(col)
                    data_df.columns = final_cols
                else:
                    data_df.columns = new_columns
                
                print(f"âœ… æ¨™é ­å·²ç°¡åŒ–ã€‚æ–°æ¨™é ­ (å‰10): {data_df.columns.to_list()[:10]}")

            # [--- é—œéµä¿®å¾©é» ---]
            # æª¢æŸ¥ 'ä»£è™Ÿ' æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœå­˜åœ¨ï¼Œå°‡å…¶æ”¹åç‚º 'ä»£ç¢¼'
            if 'ä»£è™Ÿ' in data_df.columns and 'ä»£ç¢¼' not in data_df.columns:
                print("â„¹ï¸ åµæ¸¬åˆ°æ¬„ä½ 'ä»£è™Ÿ'ï¼Œå°‡å…¶é‡æ–°å‘½åç‚º 'ä»£ç¢¼' ä»¥ç¬¦åˆ App éœ€æ±‚ã€‚")
                data_df = data_df.rename(columns={'ä»£è™Ÿ': 'ä»£ç¢¼'})
            
            # [é—œéµä¿®å¾©] ç§»é™¤ "åˆè¨ˆ" æˆ– "ç¸½è¨ˆ" åˆ—
            if 'åç¨±' in data_df.columns:
                 data_df = data_df[~data_df['åç¨±'].astype(str).str.contains('åˆè¨ˆ|ç¸½è¨ˆ', na=False)]

            # æœ€çµ‚æª¢æŸ¥ 'ä»£ç¢¼' å’Œ 'åç¨±' æ˜¯å¦å­˜åœ¨
            if 'ä»£ç¢¼' not in data_df.columns or 'åç¨±' not in data_df.columns:
                print(f"âŒ åš´é‡è­¦å‘Šï¼šç°¡åŒ–å¾Œçš„æ¨™é ­ä¸­ä»ç¼ºå°‘ 'ä»£ç¢¼' æˆ– 'åç¨±'ã€‚")
                print(f"ğŸ‘‰ ç›®å‰æ¨™é ­: {data_df.columns.to_list()}")
                return None # å›å‚³ None è®“ Streamlit çŸ¥é“å‡ºéŒ¯äº†
                
        except Exception as e:
            print(f"âŒ åœ¨è™•ç†å¤šå±¤æ¨™é ­æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            print(f"ğŸ‘‰ åŸå§‹æ¨™é ­: {data_df.columns}")
            return None # è™•ç†å¤±æ•—ï¼Œå›å‚³ None
            
    # 6. å›å‚³çµæœ (DataFrame æˆ– None)
    return data_df


# --- è…³æœ¬åŸ·è¡Œå€ (ç”¨æ–¼ç¨ç«‹æ¸¬è©¦) ---
if __name__ == "__main__":
    
    # 1. åŸ·è¡Œçˆ¬èŸ² (å‘¼å«æ–°å‡½å¼)
    data_df = scrape_goodinfo()
    
    # 2. é¡¯ç¤ºçµæœ
    if data_df is not None:
        print("\n--- çˆ¬å–çµæœ (å‰ 5 ç­†) ---")
        print(data_df.head())
        print("\n--- æ¬„ä½åç¨± ---")
        print(data_df.columns.to_list())
        
        # æª¢æŸ¥ 'ä»£ç¢¼' å’Œ 'åç¨±'
        if 'ä»£ç¢¼' in data_df.columns and 'åç¨±' in data_df.columns:
            print("\nâœ… æ¸¬è©¦æˆåŠŸï¼š'ä»£ç¢¼' å’Œ 'åç¨±' æ¬„ä½çš†å­˜åœ¨ã€‚")
        else:
            print("\nâŒ æ¸¬è©¦å¤±æ•—ï¼šç¼ºå°‘ 'ä»£ç¢¼' æˆ– 'åç¨±' æ¬„ä½ã€‚")
            
    else:
        print("\nâŒ æ¸¬è©¦åŸ·è¡Œå¤±æ•—ï¼Œæœªç²å–åˆ°ä»»ä½•è³‡æ–™ã€‚")
